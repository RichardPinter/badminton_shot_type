# src/explanation.py
"""
Explanation Generator for Badminton Player Grading System.

Generates human-readable explanations for player grades by combining insights
from the Conative Framework and the Random Forest model's predictions and
feature importances. Uses feature names aligned with 'Achievable Feature List'.

Author: Sujit
"""

import numpy as np
import pandas as pd
import logging
from typing import Dict, Optional, Any, List

# Assuming conative_framework is in the same directory or src path
try:
    from .conative_framework import ConativeFramework
except ImportError:
    from conative_framework import ConativeFramework


# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ExplanationGenerator:
    """
    Generates human-readable explanations for player grades.

    Combines conative stage assessment, ML model prediction confidence,
    and feature importance to provide a clear justification for the grade.
    Uses readable names based on the 'Achievable Feature List'.

    Attributes:
        conative_framework (ConativeFramework): An instance for accessing
            stage descriptions.
    """

    def __init__(self, conative_framework: ConativeFramework):
        """Initializes the ExplanationGenerator.

        Args:
            conative_framework: An initialized ConativeFramework instance.

        Raises:
            TypeError: If conative_framework is not a valid ConativeFramework instance.
        """
        if not isinstance(conative_framework, ConativeFramework):
            raise TypeError("ExplanationGenerator requires a valid ConativeFramework instance.")
        self.conative_framework = conative_framework
        logger.info("ExplanationGenerator initialized.")

    def _make_feature_name_readable(self, feature_name: str) -> str:
        """Converts internal flattened feature names into human-readable descriptions.

        First checks a predefined map (`name_map`) for exact matches.
        If not found, applies fallback rules (`_format_fallback_feature_name`)
        involving prefix removal and string replacements.

        Args:
            feature_name: The internal, flattened feature name string (e.g.,
                'court_coverage_metrics_coverage_area_hull').

        Returns:
            A more human-readable version of the feature name.
        """
        if not isinstance(feature_name, str):
            logger.warning(f"Received non-string feature name: {feature_name}.")
            return "Unknown Feature"

        # --- TODO: Define mappings based on the FINAL flattened feature names ---
        # This map translates the keys used internally (like METRIC_COURT_COVERAGE)
        # or generated by the flattening process into user-friendly text.
        name_map = {
            # --- Core Conative Metrics (Examples based on constants) ---
            'court_coverage_metrics_coverage_area_hull': 'Court Coverage Area (Convex Hull)',
            'body_movement_avg_body_speed_rally': 'Avg. Movement Speed (During Rally)',
            'technical_consistency_proxy_overall_consistency_score': 'Technical Consistency (Proxy Score)',
            'timing_and_intensity_play_rest_speed_ratio': 'Play/Rest Intensity Ratio',
            'tactical_proxies_composite_awareness_score': 'Tactical Awareness (Composite Score)',

            # --- Spatial Features (Examples) ---
            'spatial_angle_elbow_angle_L_mean': 'Avg. Elbow Angle (Left)',
            'spatial_angle_elbow_angle_L_std': 'Elbow Angle Variability (Left)',
            'spatial_angle_knee_angle_R_mean': 'Avg. Knee Angle (Right)',
            'spatial_angle_knee_angle_R_std': 'Knee Angle Variability (Right)',
            'spatial_dist_norm_elbow_to_wrist_L_mean': 'Avg. Norm. Forearm Extension (Left)',
            'court_positioning_avg_position_y': 'Avg. Vertical Court Position',
            'court_positioning_zone_occupancy_freq_5': 'Time Spent in Center Mid-Court (Zone 5)', # Example zone

            # --- Temporal Features (Examples) ---
            'temporal_vel_wrist_velocity_R_max': 'Max Wrist Speed (Right)',
            'temporal_vel_ankle_velocity_L_mean': 'Avg. Ankle Speed (Left)',
            'temporal_accel_wrist_acceleration_R_max': 'Max Wrist Acceleration (Right)',
            'body_movement_movement_distance_per_rally_avg': 'Avg. Distance Covered per Rally',
            'timing_and_intensity_avg_rally_duration': 'Avg. Rally Duration',
            'timing_and_intensity_avg_time_between_shots': 'Avg. Time Between Player Shots',

            # --- Performance Metrics (Examples) ---
            'stroke_profile_stroke_dist_smash': 'Proportion of Smashes',
            'stroke_profile_stroke_dist_clear': 'Proportion of Clears',
            'stroke_profile_unknown_stroke_proportion': 'Proportion of Unknown Strokes',
            'technical_consistency_proxy_elbow_angle_variability': 'Elbow Angle Variability (Hitting)', # More specific proxy
            'tactical_proxies_net_play_frequency': 'Net Play Frequency',
            'tactical_proxies_offensive_stroke_ratio': 'Offensive Stroke Ratio',
            'court_coverage_metrics_avg_repositioning_speed': 'Avg. Repositioning Speed',

            # Add mappings for ALL features expected from the flattened list...
        }

        if feature_name in name_map:
            return name_map[feature_name]

        # --- Fallback Rules (if name not in map) ---
        return self._format_fallback_feature_name(feature_name)

    def _format_fallback_feature_name(self, feature_name: str) -> str:
        """Applies fallback rules to format a feature name not found in name_map.

        Removes common prefixes (like 'performance_metrics_', 'spatial_') and
        replaces underscores with spaces, applies title case, and standardizes
        abbreviations (like 'Std' to 'Variability').

        Args:
            feature_name: The feature name string after failing the primary map lookup.

        Returns:
            A formatted, more readable feature name string.
        """
        # logger.debug(f"Applying fallback rules for feature name: {feature_name}")
        readable_name = feature_name
        # Remove known prefixes first
        prefixes = ['performance_metrics_', 'court_coverage_metrics_', 'tactical_proxies_',
                    'technical_consistency_proxy_', 'stroke_profile_', 'timing_and_intensity_',
                    'body_movement_', 'joint_accelerations_', 'joint_velocities_',
                    'court_positioning_', 'relative_joint_distances_', 'joint_angles_',
                    'spatial_', 'temporal_', 'perf_', 'feat_']
        for prefix in prefixes:
            if readable_name.startswith(prefix):
                readable_name = readable_name[len(prefix):]
                break

        # General replacements
        readable_name = readable_name.replace('_', ' ').title()
        replacements = {'Mean': 'Average', 'Std': 'Variability', 'Min': 'Minimum', 'Max': 'Maximum',
                        'Accel': 'Acceleration', 'Vel': 'Velocity', 'Dist': 'Distance', 'Pos': 'Position',
                        'Freq': 'Frequency', 'L': '(Left)', 'R': '(Right)', 'Avg': 'Average',
                        'Norm ': 'Normalized '}
        for old, new in replacements.items():
             # Use word boundaries for some replacements to avoid partial matches (e.g., 'Std' in 'Standard')
             if old in ['Std', 'Min', 'Max', 'Avg']:
                  readable_name = readable_name.replace(f' {old}', f' {new}') # Replace if preceded by space
                  if readable_name.startswith(old): # Replace if at start
                       readable_name = readable_name.replace(old, new, 1)
             else:
                  readable_name = readable_name.replace(old, new)


        return ' '.join(readable_name.split()) # Clean up extra spaces


    def generate_explanation(self,
                             grade: str,
                             confidence: float,
                             conative_stage: int,
                             feature_importance: Optional[Dict[str, float]],
                             features_vector: Optional[pd.Series] = None,
                             top_n_features: int = 5) -> str:
        """Generates a comprehensive explanation report for a player's grade.

        Combines the predicted grade, confidence, conative stage analysis,
        grade interpretation, key influencing factors (top features from the
        ML model if available), and general recommendations into a formatted string.

        Args:
            grade: The predicted grade string ('A'-'D' or 'N/A').
            confidence: The confidence score (0.0-1.0) for the prediction.
            conative_stage: The determined conative stage (1-5).
            feature_importance: A dictionary mapping selected feature names to their
                importance scores (e.g., from GradingModel.get_feature_importance()).
                Can be None if not applicable.
            features_vector: An optional pandas Series containing the *processed*
                feature values used for the ML prediction (indexed by feature name).
                Used to display values alongside importance scores.
            top_n_features: The maximum number of top important features to list.

        Returns:
            A multi-line string containing the formatted explanation report.
        """
        logger.info(f"Generating explanation for Grade: {grade}, Stage: {conative_stage}, Confidence: {confidence:.2f}")

        report_parts = ["**Player Grading Report**", "="*25]
        report_parts.append(f"**Assigned Grade:** {grade}")
        report_parts.append(f"**Confidence Score:** {confidence:.1%}")

        report_parts.append("\n**Conative Framework Analysis:**")
        stage_description = self.conative_framework.get_stage_description(conative_stage)
        report_parts.append(f"- **Determined Stage:** {conative_stage} ({stage_description})")

        report_parts.append("\n**Grade Interpretation:**")
        report_parts.append(f"- {self._get_grade_specific_interpretation(grade)}")

        report_parts.append("\n**Key Factors Influencing Grade (Machine Learning Model):**")
        if feature_importance and isinstance(feature_importance, dict) and grade != 'N/A':
            if not feature_importance:
                 report_parts.append("- Feature importance data not available for this prediction.")
            else:
                try:
                    sorted_features = sorted(feature_importance.items(), key=lambda item: item[1], reverse=True)
                    num_to_show = min(top_n_features, len(sorted_features))
                    report_parts.append(f"- Top {num_to_show} contributing factors:")

                    for i, (feature, importance) in enumerate(sorted_features[:num_to_show]):
                        if importance < 0.001: continue # Skip features with negligible importance
                        readable_name = self._make_feature_name_readable(feature)
                        factor_line = f"  {i+1}. **{readable_name}** (Importance: {importance:.3f})"

                        if features_vector is not None and isinstance(features_vector, pd.Series):
                            feature_value = features_vector.get(feature)
                            if pd.notna(feature_value):
                                factor_line += f" - Value: {feature_value:.2f}"
                            else: factor_line += " - (Value: N/A)"
                        report_parts.append(factor_line)
                    if num_to_show == 0:
                         report_parts.append("  (No features with significant importance found)")

                except Exception as e:
                     logger.error(f"Error processing feature importance: {e}", exc_info=True)
                     report_parts.append("- Error encountered while processing feature importance.")
        elif grade != 'N/A':
            report_parts.append("- Feature importance data not applicable (e.g., model not trained or used).")
        else: report_parts.append("- Not applicable due to grading error.")

        report_parts.append("\n**Recommendations for Improvement:**")
        recommendations = self._get_recommendations(grade, conative_stage)
        if recommendations: report_parts.extend([f"- {rec}" for rec in recommendations])
        else: report_parts.append("- No specific recommendations available.")

        return "\n".join(report_parts)

    def _get_grade_specific_interpretation(self, grade: str) -> str:
        """Provides a brief interpretation of what the assigned grade implies.

        Args:
            grade: The assigned grade string.

        Returns:
            A short interpretive sentence for the grade.
        """
        interpretations = {
            'A': "Player demonstrates expert-level performance...", # Keep concise
            'B': "Player shows advanced abilities...",
            'C': "Player exhibits intermediate skills...",
            'D': "Player operates at a basic or functional level...",
            'N/A': "Grade could not be determined. Review input or model status."
        } # Use full descriptions from previous version if preferred
        return interpretations.get(grade, interpretations['N/A'])

    def _get_recommendations(self, grade: str, conative_stage: int) -> List[str]:
        """Generates tailored recommendations based on the assigned grade.

        Provides generic recommendations mapped to each grade level.
        (Currently does not use `conative_stage` for further refinement).

        Args:
            grade: The assigned grade string.
            conative_stage: The determined conative stage (currently unused).

        Returns:
            A list of recommendation strings.
        """
        reco_map = {
            'A': ["Focus on advanced tactical adaptability...", "Refine deception techniques...", "Analyze high-level matches..."],
            'B': ["Improve anticipation and speed of decision-making...", "Increase consistency of advanced shots...", "Enhance court coverage speed..."],
            'C': ["Develop a wider range of shots and construct tactical sequences.", "Increase consistency of fundamental strokes...", "Improve footwork patterns..."],
            'D': ["Master fundamental techniques with consistency.", "Develop basic footwork for court movement.", "Focus on achieving consistent rallies..."],
            'N/A': ["Cannot provide recommendations due to grading error."]
        }
        recommendations = reco_map.get(grade, reco_map['N/A'])
        # Optional: Add stage-specific nuances here
        # logger.debug(f"Generated {len(recommendations)} recommendations for Grade {grade}, Stage {conative_stage}.")
        return recommendations

